{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def load_data(file_path: str, file_type: str = \"csv\") -> object:\n",
    "    \"\"\"Carrega dados a partir de um arquivo\"\"\"\n",
    "    if file_type == \"csv\":\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_type == \"json\":\n",
    "        df = pd.read_json(file_path)\n",
    "    elif file_type == \"parquet\":\n",
    "        df = pd.read_parquet(file_path)\n",
    "    elif file_type == \"excel\":\n",
    "        dfs = []\n",
    "        sheets = pd.ExcelFile(file_path).sheet_names\n",
    "        print(sheets)\n",
    "        for sheet in sheets:\n",
    "            dfs.append(pd.read_excel(file_path, sheet_name=sheet, skiprows=1))\n",
    "        return dfs\n",
    "    else:\n",
    "        raise ValueError(\"Formato de arquivo não suportado\")\n",
    "    \n",
    "    return dfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df: list) -> pd.DataFrame:\n",
    "    \"\"\"Realiza transformações nos dados\"\"\"\n",
    "    dff = pd.concat(df[:6]).copy()\n",
    "    dff = dff.dropna()\n",
    "    dff[\"data_processada\"] = datetime.now()  # Adicionando uma coluna com a data do processamento\n",
    "    dff[\"nova_coluna\"] = dff[\"coluna_existente\"] * 2  # Exemplo de nova coluna\n",
    "\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação e export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(df: pd.DataFrame) -> bool:\n",
    "    \"\"\"Valida os dados\"\"\"\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        return False\n",
    "    if df.empty:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def save_data(df: pd.DataFrame, output_path: str):\n",
    "    \"\"\"Salva os dados processados em Parquet\"\"\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    df.to_parquet(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_pipeline(input_file: str, output_file: str, file_type:str = 'csv'):\n",
    "    # Pipeline de tratamento\n",
    "    df = load_data(input_file, file_type)\n",
    "    df = transform_data(df)\n",
    "\n",
    "    # if validate_data(df):\n",
    "    #     save_data(df, output_file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executa o Pipeline de transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1A', '1B', '1C', '1D', '1E', '1F', 'Tabela_din_mica_1', 'Aulas_assistidas', 'Par_metros']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'coluna_existente'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/DataBridgeX2/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'coluna_existente'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/raw/sheets/dados_google_sheets.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                 \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/processed/dados_processados.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexcel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[50], line 4\u001b[0m, in \u001b[0;36mexecute_pipeline\u001b[0;34m(input_file, output_file, file_type)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute_pipeline\u001b[39m(input_file: \u001b[38;5;28mstr\u001b[39m, output_file: \u001b[38;5;28mstr\u001b[39m, file_type:\u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Pipeline de tratamento\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m load_data(input_file, file_type)\n\u001b[0;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# if validate_data(df):\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#     save_data(df, output_file)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "Cell \u001b[0;32mIn[48], line 6\u001b[0m, in \u001b[0;36mtransform_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      4\u001b[0m dff \u001b[38;5;241m=\u001b[39m dff\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      5\u001b[0m dff[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_processada\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()  \u001b[38;5;66;03m# Adicionando uma coluna com a data do processamento\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m dff[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnova_coluna\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdff\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoluna_existente\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Exemplo de nova coluna\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/Documents/DataBridgeX2/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/DataBridgeX2/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'coluna_existente'"
     ]
    }
   ],
   "source": [
    "df = execute_pipeline(input_file='../data/raw/sheets/dados_google_sheets.xlsx', \n",
    "                 output_file='../data/processed/dados_processados.parquet',\n",
    "                 file_type='excel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA</th>\n",
       "      <th>Período</th>\n",
       "      <th>Dispersão Geral</th>\n",
       "      <th>Intervenção Geral</th>\n",
       "      <th>Dispersão</th>\n",
       "      <th>Sono</th>\n",
       "      <th>Conversa</th>\n",
       "      <th>Intervenções</th>\n",
       "      <th>Saídas</th>\n",
       "      <th>Pergunta de Verificação</th>\n",
       "      <th>Pergunta de Ampliação</th>\n",
       "      <th>Contribuição espontânea</th>\n",
       "      <th>Participação solicitada</th>\n",
       "      <th>Não fez a atividade</th>\n",
       "      <th>Dispersão durante atividade</th>\n",
       "      <th>Conversa durante atividade</th>\n",
       "      <th>Pergunta durante atividade para prof/assistente</th>\n",
       "      <th>Pergunta para colega(s)</th>\n",
       "      <th>Tirou dúvida de colega(s)</th>\n",
       "      <th>Dispersão geral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1701.000000</td>\n",
       "      <td>1409.000000</td>\n",
       "      <td>456.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>163958.386831</td>\n",
       "      <td>2.559262</td>\n",
       "      <td>1.629386</td>\n",
       "      <td>1.990361</td>\n",
       "      <td>1.260417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.772973</td>\n",
       "      <td>1.244898</td>\n",
       "      <td>1.032787</td>\n",
       "      <td>1.510490</td>\n",
       "      <td>1.045455</td>\n",
       "      <td>1.304878</td>\n",
       "      <td>1.018519</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.322581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35836.180845</td>\n",
       "      <td>1.336576</td>\n",
       "      <td>1.426874</td>\n",
       "      <td>1.338722</td>\n",
       "      <td>0.528051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.124009</td>\n",
       "      <td>0.480044</td>\n",
       "      <td>0.179556</td>\n",
       "      <td>1.013063</td>\n",
       "      <td>0.213201</td>\n",
       "      <td>0.639958</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>1.252953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>110102.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>130757.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>160478.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>181250.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>250398.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RA      Período  Dispersão Geral  Intervenção Geral  \\\n",
       "count    1701.000000  1409.000000       456.000000         415.000000   \n",
       "mean   163958.386831     2.559262         1.629386           1.990361   \n",
       "std     35836.180845     1.336576         1.426874           1.338722   \n",
       "min    110102.000000     1.000000         1.000000           1.000000   \n",
       "25%    130757.000000     1.000000         1.000000           1.000000   \n",
       "50%    160478.000000     2.000000         1.000000           1.000000   \n",
       "75%    181250.000000     3.000000         2.000000           2.000000   \n",
       "max    250398.000000     6.000000         6.000000           5.000000   \n",
       "\n",
       "       Dispersão  Sono    Conversa  Intervenções     Saídas  \\\n",
       "count  96.000000   0.0  185.000000     49.000000  61.000000   \n",
       "mean    1.260417   NaN    1.772973      1.244898   1.032787   \n",
       "std     0.528051   NaN    1.124009      0.480044   0.179556   \n",
       "min     1.000000   NaN    1.000000      1.000000   1.000000   \n",
       "25%     1.000000   NaN    1.000000      1.000000   1.000000   \n",
       "50%     1.000000   NaN    1.000000      1.000000   1.000000   \n",
       "75%     1.000000   NaN    2.000000      1.000000   1.000000   \n",
       "max     3.000000   NaN    6.000000      3.000000   2.000000   \n",
       "\n",
       "       Pergunta de Verificação  Pergunta de Ampliação  \\\n",
       "count               143.000000              22.000000   \n",
       "mean                  1.510490               1.045455   \n",
       "std                   1.013063               0.213201   \n",
       "min                   1.000000               1.000000   \n",
       "25%                   1.000000               1.000000   \n",
       "50%                   1.000000               1.000000   \n",
       "75%                   2.000000               1.000000   \n",
       "max                   9.000000               2.000000   \n",
       "\n",
       "       Contribuição espontânea  Participação solicitada  Não fez a atividade  \\\n",
       "count               164.000000                54.000000                  1.0   \n",
       "mean                  1.304878                 1.018519                  1.0   \n",
       "std                   0.639958                 0.136083                  NaN   \n",
       "min                   1.000000                 1.000000                  1.0   \n",
       "25%                   1.000000                 1.000000                  1.0   \n",
       "50%                   1.000000                 1.000000                  1.0   \n",
       "75%                   1.000000                 1.000000                  1.0   \n",
       "max                   4.000000                 2.000000                  1.0   \n",
       "\n",
       "       Dispersão durante atividade  Conversa durante atividade  \\\n",
       "count                         51.0                         5.0   \n",
       "mean                           1.0                         1.0   \n",
       "std                            0.0                         0.0   \n",
       "min                            1.0                         1.0   \n",
       "25%                            1.0                         1.0   \n",
       "50%                            1.0                         1.0   \n",
       "75%                            1.0                         1.0   \n",
       "max                            1.0                         1.0   \n",
       "\n",
       "       Pergunta durante atividade para prof/assistente  \\\n",
       "count                                        28.000000   \n",
       "mean                                          1.285714   \n",
       "std                                           0.534522   \n",
       "min                                           1.000000   \n",
       "25%                                           1.000000   \n",
       "50%                                           1.000000   \n",
       "75%                                           1.250000   \n",
       "max                                           3.000000   \n",
       "\n",
       "       Pergunta para colega(s)  Tirou dúvida de colega(s)  Dispersão geral  \n",
       "count                      5.0                   7.000000       124.000000  \n",
       "mean                       1.0                   1.142857         2.322581  \n",
       "std                        0.0                   0.377964         1.252953  \n",
       "min                        1.0                   1.000000         1.000000  \n",
       "25%                        1.0                   1.000000         1.000000  \n",
       "50%                        1.0                   1.000000         2.000000  \n",
       "75%                        1.0                   1.000000         4.000000  \n",
       "max                        1.0                   2.000000         4.000000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(df[:6]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
